
''' Build models to detect Algorithmically Generated Domain Names (DGA).
    We're trying to classify domains as being 'legit' or having a high probability
    of being generated by a DGA (Dynamic Generation Algorithm). We have 'legit' in
    quotes as we're using the domains in Alexa as the 'legit' set.
'''

import os, sys
import traceback
import json
import optparse
import pickle
import collections
import sklearn
import numpy as np
import tldextract
import math

model = {}
dga_inited = False

# Okay for this model we need the 2LD and nothing else
def domain_extract(url):
    ext = tldextract.extract(url)
    if (not ext.suffix):
        print '(info) Malformed URL: %s' % (url)

    return ext.domain

# Entropy calc (this must match model_gen)
def entropy(s):
    p, lns = collections.Counter(s), float(len(s))
    return -sum( count/lns * math.log(count/lns, 2) for count in p.values())

# Evaluate the incoming domain
def evaluate_url(model, url):

    domain = domain_extract(url)
    alexa_match = model['alexa_counts'] * model['alexa_vc'].transform([url]).T
    dict_match = model['dict_counts'] * model['dict_vc'].transform([url]).T

    # Assemble feature matrix (for just one domain)
    X = [len(domain), entropy(domain), alexa_match, dict_match]
    y_pred = model['clf'].predict(X)[0]
    return y_pred

# Evaluate the incoming domains
def evaluate_url_list(model, url_list):

    domain_list = [domain_extract(url) for url in url_list]
    domain_length = [len(domain) for domain in domain_list]
    domain_entropy = [entropy(domain) for domain in domain_list]
    alexa_matches = model['alexa_counts'] * model['alexa_vc'].transform(url_list).T
    dict_matches = model['dict_counts'] * model['dict_vc'].transform(url_list).T

    # Assemble feature matrix
    X = np.array([domain_length, domain_entropy, alexa_matches, dict_matches])
    X = X.T

    # Get the prediction vector
    y_pred = model['clf'].predict(X)
    return y_pred

def load_model_from_disk(name, model_dir='models'):

    # Model directory is relative to this file
    model_path = os.path.join(model_dir, name+'.model')

    # Put a try/except around the model load in case it fails
    try:
        model = pickle.loads(open(model_path,'rb').read())
    except:
        print 'Could not load model: %s from directory %s!' % (name, model_path)
        return None

    return model

def is_dga_inited():
    global dga_inited
    if dga_inited == True:
        return True
    else:
        return False

def set_dga_inited():
    global dga_inited
    dga_inited = True

def init():
    global model

    if is_dga_inited() == True:
        return

    set_dga_inited()

    try: # Pokemon exception handling

        # Load up all the models
        print 'Loading Models'

        current_path = os.path.split(os.path.realpath(__file__))[0]

        model_path = current_path + '/models/'

        clf = load_model_from_disk('dga_model_random_forest', model_path)
        alexa_vc = load_model_from_disk('dga_model_alexa_vectorizor', model_path)
        alexa_counts = load_model_from_disk('dga_model_alexa_counts', model_path)
        dict_vc = load_model_from_disk('dga_model_dict_vectorizor', model_path)
        dict_counts = load_model_from_disk('dga_model_dict_counts', model_path)
        model = {'clf':clf, 'alexa_vc':alexa_vc, 'alexa_counts':alexa_counts,
                 'dict_vc':dict_vc, 'dict_counts':dict_counts}

    except KeyboardInterrupt:
        print 'Goodbye Cruel World...'
    except Exception, error:
        traceback.print_exc()
        print '(Exception):, %s' % (str(error))

def check(domain):
    global model
    init()
    return evaluate_url(model, domain)
